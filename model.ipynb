{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4d5a7a",
   "metadata": {},
   "source": [
    "## ML Model\n",
    "### Constructing, training and Evaluation of at least three different models\n",
    "\n",
    "### Cunstruction:\n",
    "- Pipeline of multiple different ML-models\n",
    "\n",
    "### Training:\n",
    "\n",
    "- Training the different models with the splitted training dataset. Combining different combinations of features. USe vizualisation to see correlence between feature and goals scored in a match.\n",
    "\n",
    "    - Models:\n",
    "    - Multiple Linear Regression\n",
    "    - Logistic Regression\n",
    "    - KNN : KNearestNeighbours\n",
    "        - Multiple k's\n",
    "    - DecisionTreeRegressor\n",
    "    - RandomForestRegressor\n",
    "    - DecisionTreeClassifier\n",
    "    - RandomForestClassifier\n",
    "        - Different estimators (Ex n_estimators = 500)\n",
    "        - mse = log_loss(y_val, pred)\n",
    "    - MLPClassifier\n",
    "    \n",
    "#### Evaluation:\n",
    "- Evaluate the different trained models with the validation dataset, check for over-/underfit:\n",
    "    Methods:\n",
    "    - MSE\n",
    "        - Lower == Better\n",
    "    - Delta\n",
    "        - Lower == Lower MSE will give lower test_rmse hence lower delta better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b30e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression             as LR\n",
    "from sklearn.linear_model import LogisticRegression           as LogReg\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor                as DTR\n",
    "from sklearn.ensemble import RandomForestRegressor            as RFR\n",
    "from sklearn.neighbors import KNeighborsRegressor             as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier               as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier           as RFC\n",
    "from sklearn.neural_network import MLPClassifier              as MLPC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import plotly.figure_factory as ff\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4812db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['HomeGround', 'AvgGoalsScored_90', 'GlsRatio', '%FPla', 'Avg_Age', 'OppGlsAgst90', 'tablePos', 'points']\n",
    "## Reading the data created in the preparation stored in two CSV files\n",
    "games = pd.read_csv(\"training_data_games.csv\")\n",
    "test_games = pd.read_csv(\"test_data_games.csv\")\n",
    "\n",
    "X = games[numeric_features]\n",
    "Y = games['Goals']\n",
    "X_train, X_valtest, Y_train, y_valtest = train_test_split(X, Y, test_size=0.3, random_state=69)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_valtest, y_valtest, test_size=0.5, random_state=69)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3568220a",
   "metadata": {},
   "source": [
    "## Creating a dummy-model, where the predicted score is a random number from a normal distribution from 0 - 6 (Max and min values of train-data). By doing this 30 times and taking the average of the RMSEs of the rounds, we get a more trustworthy RMSE to use for later evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e1ee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from random normal-distribution: 2.569070225857679\n"
     ]
    }
   ],
   "source": [
    "def do_random_normal_predictions():\n",
    "    random_predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        random_predictions.append(random.uniform(0, max(Y_train)))\n",
    "\n",
    "    random_prediction_RMSE = mean_squared_error(\n",
    "        Y_test, \n",
    "        random_predictions, \n",
    "        squared=False\n",
    "    )\n",
    "    return random_prediction_RMSE\n",
    "normal_list = [do_random_normal_predictions() for x in range(30)]\n",
    "avg_random_prediction_RMSE = np.average(normal_list)\n",
    "print(f\"RMSE from random normal-distribution: {avg_random_prediction_RMSE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f7f40",
   "metadata": {},
   "source": [
    "## Creating a second dummy-model with the average amount of goals from the test-dataset, and comparing this with the actual Y_test-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691ae687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average goals scored from train-data: 1.5591\n",
      "RMSE from average prediction: 1.448303424700777\n"
     ]
    }
   ],
   "source": [
    "avg_of_train_data = round(np.average(Y_train), 4)\n",
    "print(f\"Average goals scored from train-data: {avg_of_train_data}\")\n",
    "avg_predictions = [avg_of_train_data for i in range(len(Y_val))]\n",
    "average_prediction_RMSE = mean_squared_error(\n",
    "    Y_val, \n",
    "    avg_predictions, \n",
    "    squared=False\n",
    ")\n",
    "print(f\"RMSE from average prediction: {average_prediction_RMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c4e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputers and different models\n",
    "imputers = {\n",
    "    'median': SimpleImputer(strategy='median'),\n",
    "    'mean': SimpleImputer(strategy='mean'),\n",
    "    'most_frequent' : SimpleImputer(strategy='most_frequent')\n",
    "}\n",
    "models = {'LinearRegression' : LR(positive=True),\n",
    "          'LogisticRegression' : LogReg(),\n",
    "          'DecisionTreeRegressor' : DTR(),\n",
    "          'RandomForestRegressor_n100' : RFR(n_estimators = 100),\n",
    "          'RandomForestRegressor_n200' : RFR(n_estimators = 200),\n",
    "          'RandomForestRegressor_n300' : RFR(n_estimators = 300),\n",
    "          'RandomForestRegressor_n400' : RFR(n_estimators = 400),\n",
    "          'RandomForestRegressor_n500' : RFR(n_estimators = 500),\n",
    "          'KNeighborsRegressor_03n' : KNN(n_neighbors=3),\n",
    "          'KNeighborsRegressor_05n' : KNN(n_neighbors=5),\n",
    "          'KNeighborsRegressor_07n' : KNN(n_neighbors=7),\n",
    "          'KNeighborsRegressor_10n' : KNN(n_neighbors=10),\n",
    "          'KNeighborsRegressor_13n' : KNN(n_neighbors=13),\n",
    "          'DecisionTreeClassifier' : DTC(), \n",
    "          'RandomForestClassifier_250' : RFC(n_estimators=250),\n",
    "          'RandomForestClassifier_500' : RFC(n_estimators=500),\n",
    "          'RandomForestClassifier_750' : RFC(n_estimators=750),\n",
    "          'RandomForestClassifier_1000' : RFC(n_estimators=1000),\n",
    "             }\n",
    "scalers = {\n",
    "    'standard' : StandardScaler(copy = True, with_mean = True, with_std = True),\n",
    "    'MinMax'   : MinMaxScaler(),\n",
    "    'MaxAbs'   : MaxAbsScaler()\n",
    "}\n",
    "all_combinations = []\n",
    "## Creating all combinations of imputers, models and scalers to find the optimal combination\n",
    "for imp in imputers.items():\n",
    "    for model in models.items():\n",
    "        for scaler in scalers.items():\n",
    "            this_set = [imp, model, scaler]\n",
    "            all_combinations.append(this_set)\n",
    "            \n",
    "\n",
    "\n",
    "numeric_features = ['HomeGround', 'AvgGoalsScored_90', 'GlsRatio', '%FPla', 'Avg_Age', 'OppGlsAgst90', 'tablePos', 'points']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a204652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = {imputer_key + '_' + model_key + \"_\" + scaler_key: Pipeline(\n",
    "        steps=[\n",
    "            ('preprocess', ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', Pipeline(\n",
    "                        steps = [\n",
    "                            ('impute', imputer), \n",
    "                            ('scaler', StandardScaler())\n",
    "                        ]),\n",
    "                     numeric_features)\n",
    "                ]\n",
    "            )\n",
    "            ),\n",
    "            ('regress', model)\n",
    "        ]\n",
    "    )\n",
    "             for (imputer_key, imputer), (model_key, model), (scaler_key, scaler) in all_combinations}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e51a342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "validation_rmse = pd.DataFrame(\n",
    "    {key: mean_squared_error(\n",
    "        Y_val, \n",
    "        pipe.fit(X_train, Y_train).predict(X_val), \n",
    "        squared=False\n",
    "    )\n",
    "     for key, pipe in pipes.items()}.items(),\n",
    "    columns=['model', 'rmse']\n",
    ")\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92853c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Validation-RMSE: \n",
      "model        most_frequent_LinearRegression_standard\n",
      "rmse                                         1.30743\n",
      "test_rmse                                   1.544924\n",
      "delta                                       0.237494\n",
      "Name: 108, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>models_w_Attributes</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>median_LinearRegression_standard</td>\n",
       "      <td>1.302203</td>\n",
       "      <td>LinearRegression(positive=True)</td>\n",
       "      <td>1.550734</td>\n",
       "      <td>0.248530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>median_LinearRegression_MinMax</td>\n",
       "      <td>1.302203</td>\n",
       "      <td>LinearRegression(positive=True)</td>\n",
       "      <td>1.550734</td>\n",
       "      <td>0.248530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>median_LinearRegression_MaxAbs</td>\n",
       "      <td>1.302203</td>\n",
       "      <td>LinearRegression(positive=True)</td>\n",
       "      <td>1.550734</td>\n",
       "      <td>0.248530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>median_LogisticRegression_standard</td>\n",
       "      <td>1.453444</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.942936</td>\n",
       "      <td>0.489492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>median_LogisticRegression_MinMax</td>\n",
       "      <td>1.453444</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.942936</td>\n",
       "      <td>0.489492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>median_LogisticRegression_MaxAbs</td>\n",
       "      <td>1.453444</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.942936</td>\n",
       "      <td>0.489492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>median_DecisionTreeRegressor_standard</td>\n",
       "      <td>1.501157</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>2.078912</td>\n",
       "      <td>0.577755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>median_DecisionTreeRegressor_MinMax</td>\n",
       "      <td>1.558356</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>2.078912</td>\n",
       "      <td>0.520556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>median_DecisionTreeRegressor_MaxAbs</td>\n",
       "      <td>1.542230</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>2.078912</td>\n",
       "      <td>0.536682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>median_RandomForestRegressor_n100_standard</td>\n",
       "      <td>1.321711</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.884003</td>\n",
       "      <td>0.562292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>median_RandomForestRegressor_n100_MinMax</td>\n",
       "      <td>1.303534</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.884003</td>\n",
       "      <td>0.580469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>median_RandomForestRegressor_n100_MaxAbs</td>\n",
       "      <td>1.313665</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.884003</td>\n",
       "      <td>0.570339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>median_RandomForestRegressor_n200_standard</td>\n",
       "      <td>1.302207</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.873733</td>\n",
       "      <td>0.571526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>median_RandomForestRegressor_n200_MinMax</td>\n",
       "      <td>1.307043</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.873733</td>\n",
       "      <td>0.566689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>median_RandomForestRegressor_n200_MaxAbs</td>\n",
       "      <td>1.305169</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.873733</td>\n",
       "      <td>0.568564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>median_RandomForestRegressor_n300_standard</td>\n",
       "      <td>1.303589</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.867207</td>\n",
       "      <td>0.563618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>median_RandomForestRegressor_n300_MinMax</td>\n",
       "      <td>1.302185</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.867207</td>\n",
       "      <td>0.565022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>median_RandomForestRegressor_n300_MaxAbs</td>\n",
       "      <td>1.300560</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.867207</td>\n",
       "      <td>0.566646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>median_RandomForestRegressor_n400_standard</td>\n",
       "      <td>1.310178</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.875839</td>\n",
       "      <td>0.565661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>median_RandomForestRegressor_n400_MinMax</td>\n",
       "      <td>1.300976</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.875839</td>\n",
       "      <td>0.574863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>median_RandomForestRegressor_n400_MaxAbs</td>\n",
       "      <td>1.303488</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.875839</td>\n",
       "      <td>0.572351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>median_RandomForestRegressor_n500_standard</td>\n",
       "      <td>1.309877</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.873696</td>\n",
       "      <td>0.563818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>median_RandomForestRegressor_n500_MinMax</td>\n",
       "      <td>1.300604</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.873696</td>\n",
       "      <td>0.573092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>median_RandomForestRegressor_n500_MaxAbs</td>\n",
       "      <td>1.304265</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.873696</td>\n",
       "      <td>0.569431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>median_KNeighborsRegressor_03n_standard</td>\n",
       "      <td>1.538849</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=3)</td>\n",
       "      <td>1.907223</td>\n",
       "      <td>0.368374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>median_KNeighborsRegressor_03n_MinMax</td>\n",
       "      <td>1.538849</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=3)</td>\n",
       "      <td>1.907223</td>\n",
       "      <td>0.368374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>median_KNeighborsRegressor_03n_MaxAbs</td>\n",
       "      <td>1.538849</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=3)</td>\n",
       "      <td>1.907223</td>\n",
       "      <td>0.368374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>median_KNeighborsRegressor_05n_standard</td>\n",
       "      <td>1.338656</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>1.749143</td>\n",
       "      <td>0.410487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>median_KNeighborsRegressor_05n_MinMax</td>\n",
       "      <td>1.338656</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>1.749143</td>\n",
       "      <td>0.410487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>median_KNeighborsRegressor_05n_MaxAbs</td>\n",
       "      <td>1.338656</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>1.749143</td>\n",
       "      <td>0.410487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>median_KNeighborsRegressor_07n_standard</td>\n",
       "      <td>1.312227</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=7)</td>\n",
       "      <td>1.660541</td>\n",
       "      <td>0.348315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>median_KNeighborsRegressor_07n_MinMax</td>\n",
       "      <td>1.312227</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=7)</td>\n",
       "      <td>1.660541</td>\n",
       "      <td>0.348315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>median_KNeighborsRegressor_07n_MaxAbs</td>\n",
       "      <td>1.312227</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=7)</td>\n",
       "      <td>1.660541</td>\n",
       "      <td>0.348315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>median_KNeighborsRegressor_10n_standard</td>\n",
       "      <td>1.360698</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>1.624846</td>\n",
       "      <td>0.264148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>median_KNeighborsRegressor_10n_MinMax</td>\n",
       "      <td>1.360698</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>1.624846</td>\n",
       "      <td>0.264148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>median_KNeighborsRegressor_10n_MaxAbs</td>\n",
       "      <td>1.360698</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>1.624846</td>\n",
       "      <td>0.264148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>median_KNeighborsRegressor_13n_standard</td>\n",
       "      <td>1.340924</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=13)</td>\n",
       "      <td>1.608732</td>\n",
       "      <td>0.267808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>median_KNeighborsRegressor_13n_MinMax</td>\n",
       "      <td>1.340924</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=13)</td>\n",
       "      <td>1.608732</td>\n",
       "      <td>0.267808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>median_KNeighborsRegressor_13n_MaxAbs</td>\n",
       "      <td>1.340924</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=13)</td>\n",
       "      <td>1.608732</td>\n",
       "      <td>0.267808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>median_DecisionTreeClassifier_standard</td>\n",
       "      <td>1.453444</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>0.667876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>median_DecisionTreeClassifier_MinMax</td>\n",
       "      <td>1.405347</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>0.715973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>median_DecisionTreeClassifier_MaxAbs</td>\n",
       "      <td>1.400893</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>0.720428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>median_RandomForestClassifier_250_standard</td>\n",
       "      <td>1.561249</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.345208</td>\n",
       "      <td>0.783958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>median_RandomForestClassifier_250_MinMax</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.345208</td>\n",
       "      <td>0.764069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>median_RandomForestClassifier_250_MaxAbs</td>\n",
       "      <td>1.565248</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.345208</td>\n",
       "      <td>0.779960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>median_RandomForestClassifier_500_standard</td>\n",
       "      <td>1.577181</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.205108</td>\n",
       "      <td>0.627927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>median_RandomForestClassifier_500_MinMax</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.205108</td>\n",
       "      <td>0.623969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>median_RandomForestClassifier_500_MaxAbs</td>\n",
       "      <td>1.577181</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.205108</td>\n",
       "      <td>0.627927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>median_RandomForestClassifier_750_standard</td>\n",
       "      <td>1.561249</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.213594</td>\n",
       "      <td>0.652345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>median_RandomForestClassifier_750_MinMax</td>\n",
       "      <td>1.592953</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.213594</td>\n",
       "      <td>0.620641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>median_RandomForestClassifier_750_MaxAbs</td>\n",
       "      <td>1.553222</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.213594</td>\n",
       "      <td>0.660372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>median_RandomForestClassifier_1000_standard</td>\n",
       "      <td>1.565248</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.224860</td>\n",
       "      <td>0.659612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>median_RandomForestClassifier_1000_MinMax</td>\n",
       "      <td>1.565248</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.224860</td>\n",
       "      <td>0.659612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>median_RandomForestClassifier_1000_MaxAbs</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.224860</td>\n",
       "      <td>0.643721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>mean_LinearRegression_standard</td>\n",
       "      <td>1.296255</td>\n",
       "      <td>LinearRegression(positive=True)</td>\n",
       "      <td>1.549145</td>\n",
       "      <td>0.252890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>mean_LinearRegression_MinMax</td>\n",
       "      <td>1.296255</td>\n",
       "      <td>LinearRegression(positive=True)</td>\n",
       "      <td>1.549145</td>\n",
       "      <td>0.252890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>mean_LinearRegression_MaxAbs</td>\n",
       "      <td>1.296255</td>\n",
       "      <td>LinearRegression(positive=True)</td>\n",
       "      <td>1.549145</td>\n",
       "      <td>0.252890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>mean_LogisticRegression_standard</td>\n",
       "      <td>1.462019</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.942936</td>\n",
       "      <td>0.480917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mean_LogisticRegression_MinMax</td>\n",
       "      <td>1.462019</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.942936</td>\n",
       "      <td>0.480917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>mean_LogisticRegression_MaxAbs</td>\n",
       "      <td>1.462019</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.942936</td>\n",
       "      <td>0.480917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mean_DecisionTreeRegressor_standard</td>\n",
       "      <td>1.693738</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>2.082667</td>\n",
       "      <td>0.388928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>mean_DecisionTreeRegressor_MinMax</td>\n",
       "      <td>1.645068</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>2.082667</td>\n",
       "      <td>0.437598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mean_DecisionTreeRegressor_MaxAbs</td>\n",
       "      <td>1.544142</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>2.082667</td>\n",
       "      <td>0.538524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>mean_RandomForestRegressor_n100_standard</td>\n",
       "      <td>1.304927</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.884190</td>\n",
       "      <td>0.579263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>mean_RandomForestRegressor_n100_MinMax</td>\n",
       "      <td>1.320018</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.884190</td>\n",
       "      <td>0.564172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>mean_RandomForestRegressor_n100_MaxAbs</td>\n",
       "      <td>1.305404</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.884190</td>\n",
       "      <td>0.578786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>mean_RandomForestRegressor_n200_standard</td>\n",
       "      <td>1.325625</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.876704</td>\n",
       "      <td>0.551079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>mean_RandomForestRegressor_n200_MinMax</td>\n",
       "      <td>1.306115</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.876704</td>\n",
       "      <td>0.570588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>mean_RandomForestRegressor_n200_MaxAbs</td>\n",
       "      <td>1.315323</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.876704</td>\n",
       "      <td>0.561381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>mean_RandomForestRegressor_n300_standard</td>\n",
       "      <td>1.317036</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.872171</td>\n",
       "      <td>0.555134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>mean_RandomForestRegressor_n300_MinMax</td>\n",
       "      <td>1.309261</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.872171</td>\n",
       "      <td>0.562909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>mean_RandomForestRegressor_n300_MaxAbs</td>\n",
       "      <td>1.310433</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.872171</td>\n",
       "      <td>0.561738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>mean_RandomForestRegressor_n400_standard</td>\n",
       "      <td>1.315460</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.878140</td>\n",
       "      <td>0.562680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>mean_RandomForestRegressor_n400_MinMax</td>\n",
       "      <td>1.307779</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.878140</td>\n",
       "      <td>0.570361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>mean_RandomForestRegressor_n400_MaxAbs</td>\n",
       "      <td>1.322402</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.878140</td>\n",
       "      <td>0.555738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mean_RandomForestRegressor_n500_standard</td>\n",
       "      <td>1.310716</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.879407</td>\n",
       "      <td>0.568692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>mean_RandomForestRegressor_n500_MinMax</td>\n",
       "      <td>1.311217</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.879407</td>\n",
       "      <td>0.568191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>mean_RandomForestRegressor_n500_MaxAbs</td>\n",
       "      <td>1.314086</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.879407</td>\n",
       "      <td>0.565321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>mean_KNeighborsRegressor_03n_standard</td>\n",
       "      <td>1.530251</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=3)</td>\n",
       "      <td>1.914129</td>\n",
       "      <td>0.383878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>mean_KNeighborsRegressor_03n_MinMax</td>\n",
       "      <td>1.530251</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=3)</td>\n",
       "      <td>1.914129</td>\n",
       "      <td>0.383878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>mean_KNeighborsRegressor_03n_MaxAbs</td>\n",
       "      <td>1.530251</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=3)</td>\n",
       "      <td>1.914129</td>\n",
       "      <td>0.383878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>mean_KNeighborsRegressor_05n_standard</td>\n",
       "      <td>1.383293</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>1.765078</td>\n",
       "      <td>0.381785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>mean_KNeighborsRegressor_05n_MinMax</td>\n",
       "      <td>1.383293</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>1.765078</td>\n",
       "      <td>0.381785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>mean_KNeighborsRegressor_05n_MaxAbs</td>\n",
       "      <td>1.383293</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>1.765078</td>\n",
       "      <td>0.381785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>mean_KNeighborsRegressor_07n_standard</td>\n",
       "      <td>1.338881</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=7)</td>\n",
       "      <td>1.652225</td>\n",
       "      <td>0.313344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>mean_KNeighborsRegressor_07n_MinMax</td>\n",
       "      <td>1.338881</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=7)</td>\n",
       "      <td>1.652225</td>\n",
       "      <td>0.313344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>mean_KNeighborsRegressor_07n_MaxAbs</td>\n",
       "      <td>1.338881</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=7)</td>\n",
       "      <td>1.652225</td>\n",
       "      <td>0.313344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>mean_KNeighborsRegressor_10n_standard</td>\n",
       "      <td>1.337068</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>1.637300</td>\n",
       "      <td>0.300232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>mean_KNeighborsRegressor_10n_MinMax</td>\n",
       "      <td>1.337068</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>1.637300</td>\n",
       "      <td>0.300232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>mean_KNeighborsRegressor_10n_MaxAbs</td>\n",
       "      <td>1.337068</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>1.637300</td>\n",
       "      <td>0.300232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>mean_KNeighborsRegressor_13n_standard</td>\n",
       "      <td>1.346264</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=13)</td>\n",
       "      <td>1.595876</td>\n",
       "      <td>0.249612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>mean_KNeighborsRegressor_13n_MinMax</td>\n",
       "      <td>1.346264</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=13)</td>\n",
       "      <td>1.595876</td>\n",
       "      <td>0.249612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>mean_KNeighborsRegressor_13n_MaxAbs</td>\n",
       "      <td>1.346264</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=13)</td>\n",
       "      <td>1.595876</td>\n",
       "      <td>0.249612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>mean_DecisionTreeClassifier_standard</td>\n",
       "      <td>1.400893</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>0.720428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>mean_DecisionTreeClassifier_MinMax</td>\n",
       "      <td>1.440486</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>0.680834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>mean_DecisionTreeClassifier_MaxAbs</td>\n",
       "      <td>1.418626</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>0.702694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>mean_RandomForestClassifier_250_standard</td>\n",
       "      <td>1.537043</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.339872</td>\n",
       "      <td>0.802829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mean_RandomForestClassifier_250_MinMax</td>\n",
       "      <td>1.573213</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.339872</td>\n",
       "      <td>0.766659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>mean_RandomForestClassifier_250_MaxAbs</td>\n",
       "      <td>1.585087</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.339872</td>\n",
       "      <td>0.754785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>mean_RandomForestClassifier_500_standard</td>\n",
       "      <td>1.585087</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.213594</td>\n",
       "      <td>0.628508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>mean_RandomForestClassifier_500_MinMax</td>\n",
       "      <td>1.569235</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.213594</td>\n",
       "      <td>0.644359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>mean_RandomForestClassifier_500_MaxAbs</td>\n",
       "      <td>1.549193</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.213594</td>\n",
       "      <td>0.664401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>mean_RandomForestClassifier_750_standard</td>\n",
       "      <td>1.569235</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.222049</td>\n",
       "      <td>0.652813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>mean_RandomForestClassifier_750_MinMax</td>\n",
       "      <td>1.585087</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.222049</td>\n",
       "      <td>0.636962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>mean_RandomForestClassifier_750_MaxAbs</td>\n",
       "      <td>1.569235</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.222049</td>\n",
       "      <td>0.652813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>mean_RandomForestClassifier_1000_standard</td>\n",
       "      <td>1.569235</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.230471</td>\n",
       "      <td>0.661235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>mean_RandomForestClassifier_1000_MinMax</td>\n",
       "      <td>1.569235</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.230471</td>\n",
       "      <td>0.661235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>mean_RandomForestClassifier_1000_MaxAbs</td>\n",
       "      <td>1.573213</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.230471</td>\n",
       "      <td>0.657258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>most_frequent_LinearRegression_standard</td>\n",
       "      <td>1.307430</td>\n",
       "      <td>LinearRegression(positive=True)</td>\n",
       "      <td>1.544924</td>\n",
       "      <td>0.237494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>most_frequent_LinearRegression_MinMax</td>\n",
       "      <td>1.307430</td>\n",
       "      <td>LinearRegression(positive=True)</td>\n",
       "      <td>1.544924</td>\n",
       "      <td>0.237494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>most_frequent_LinearRegression_MaxAbs</td>\n",
       "      <td>1.307430</td>\n",
       "      <td>LinearRegression(positive=True)</td>\n",
       "      <td>1.544924</td>\n",
       "      <td>0.237494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>most_frequent_LogisticRegression_standard</td>\n",
       "      <td>1.466288</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.936492</td>\n",
       "      <td>0.470204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>most_frequent_LogisticRegression_MinMax</td>\n",
       "      <td>1.466288</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.936492</td>\n",
       "      <td>0.470204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>most_frequent_LogisticRegression_MaxAbs</td>\n",
       "      <td>1.466288</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.936492</td>\n",
       "      <td>0.470204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>most_frequent_DecisionTreeRegressor_standard</td>\n",
       "      <td>1.556237</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>2.137463</td>\n",
       "      <td>0.581226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>most_frequent_DecisionTreeRegressor_MinMax</td>\n",
       "      <td>1.536026</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>2.137463</td>\n",
       "      <td>0.601438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>most_frequent_DecisionTreeRegressor_MaxAbs</td>\n",
       "      <td>1.556237</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>2.137463</td>\n",
       "      <td>0.581226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n100_standard</td>\n",
       "      <td>1.323340</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.870812</td>\n",
       "      <td>0.547472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n100_MinMax</td>\n",
       "      <td>1.310169</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.870812</td>\n",
       "      <td>0.560644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n100_MaxAbs</td>\n",
       "      <td>1.316054</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.870812</td>\n",
       "      <td>0.554759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n200_standard</td>\n",
       "      <td>1.327530</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.876658</td>\n",
       "      <td>0.549128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n200_MinMax</td>\n",
       "      <td>1.304002</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.876658</td>\n",
       "      <td>0.572656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n200_MaxAbs</td>\n",
       "      <td>1.310074</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.876658</td>\n",
       "      <td>0.566584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n300_standard</td>\n",
       "      <td>1.315597</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.873570</td>\n",
       "      <td>0.557973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n300_MinMax</td>\n",
       "      <td>1.307871</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.873570</td>\n",
       "      <td>0.565699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n300_MaxAbs</td>\n",
       "      <td>1.302896</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.873570</td>\n",
       "      <td>0.570673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n400_standard</td>\n",
       "      <td>1.308191</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.870013</td>\n",
       "      <td>0.561822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n400_MinMax</td>\n",
       "      <td>1.307096</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.870013</td>\n",
       "      <td>0.562917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n400_MaxAbs</td>\n",
       "      <td>1.306888</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.870013</td>\n",
       "      <td>0.563125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n500_standard</td>\n",
       "      <td>1.317732</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.872899</td>\n",
       "      <td>0.555168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n500_MinMax</td>\n",
       "      <td>1.309665</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.872899</td>\n",
       "      <td>0.563235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>most_frequent_RandomForestRegressor_n500_MaxAbs</td>\n",
       "      <td>1.305953</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>1.872899</td>\n",
       "      <td>0.566946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_03n_standard</td>\n",
       "      <td>1.419605</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=3)</td>\n",
       "      <td>1.924260</td>\n",
       "      <td>0.504656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_03n_MinMax</td>\n",
       "      <td>1.419605</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=3)</td>\n",
       "      <td>1.924260</td>\n",
       "      <td>0.504656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_03n_MaxAbs</td>\n",
       "      <td>1.419605</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=3)</td>\n",
       "      <td>1.924260</td>\n",
       "      <td>0.504656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_05n_standard</td>\n",
       "      <td>1.279258</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>1.774824</td>\n",
       "      <td>0.495566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_05n_MinMax</td>\n",
       "      <td>1.279258</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>1.774824</td>\n",
       "      <td>0.495566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_05n_MaxAbs</td>\n",
       "      <td>1.279258</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>1.774824</td>\n",
       "      <td>0.495566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_07n_standard</td>\n",
       "      <td>1.283530</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=7)</td>\n",
       "      <td>1.712946</td>\n",
       "      <td>0.429416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_07n_MinMax</td>\n",
       "      <td>1.283530</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=7)</td>\n",
       "      <td>1.712946</td>\n",
       "      <td>0.429416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_07n_MaxAbs</td>\n",
       "      <td>1.283530</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=7)</td>\n",
       "      <td>1.712946</td>\n",
       "      <td>0.429416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_10n_standard</td>\n",
       "      <td>1.332010</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>1.643700</td>\n",
       "      <td>0.311690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_10n_MinMax</td>\n",
       "      <td>1.332010</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>1.643700</td>\n",
       "      <td>0.311690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_10n_MaxAbs</td>\n",
       "      <td>1.332010</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>1.643700</td>\n",
       "      <td>0.311690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_13n_standard</td>\n",
       "      <td>1.340703</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=13)</td>\n",
       "      <td>1.595296</td>\n",
       "      <td>0.254593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_13n_MinMax</td>\n",
       "      <td>1.340703</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=13)</td>\n",
       "      <td>1.595296</td>\n",
       "      <td>0.254593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>most_frequent_KNeighborsRegressor_13n_MaxAbs</td>\n",
       "      <td>1.340703</td>\n",
       "      <td>KNeighborsRegressor(n_neighbors=13)</td>\n",
       "      <td>1.595296</td>\n",
       "      <td>0.254593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>most_frequent_DecisionTreeClassifier_standard</td>\n",
       "      <td>1.400893</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2.109502</td>\n",
       "      <td>0.708610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>most_frequent_DecisionTreeClassifier_MinMax</td>\n",
       "      <td>1.400893</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2.109502</td>\n",
       "      <td>0.708610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>most_frequent_DecisionTreeClassifier_MaxAbs</td>\n",
       "      <td>1.396424</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2.109502</td>\n",
       "      <td>0.713078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>most_frequent_RandomForestClassifier_250_standard</td>\n",
       "      <td>1.612452</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.387467</td>\n",
       "      <td>0.775016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>most_frequent_RandomForestClassifier_250_MinMax</td>\n",
       "      <td>1.612452</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.387467</td>\n",
       "      <td>0.775016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>most_frequent_RandomForestClassifier_250_MaxAbs</td>\n",
       "      <td>1.577181</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.387467</td>\n",
       "      <td>0.810286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>most_frequent_RandomForestClassifier_500_standard</td>\n",
       "      <td>1.624038</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.238861</td>\n",
       "      <td>0.614823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>most_frequent_RandomForestClassifier_500_MinMax</td>\n",
       "      <td>1.585087</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.238861</td>\n",
       "      <td>0.653775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>most_frequent_RandomForestClassifier_500_MaxAbs</td>\n",
       "      <td>1.589025</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.238861</td>\n",
       "      <td>0.649836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>most_frequent_RandomForestClassifier_750_standard</td>\n",
       "      <td>1.612452</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.238861</td>\n",
       "      <td>0.626410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>most_frequent_RandomForestClassifier_750_MinMax</td>\n",
       "      <td>1.577181</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.238861</td>\n",
       "      <td>0.661680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>most_frequent_RandomForestClassifier_750_MaxAbs</td>\n",
       "      <td>1.612452</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.238861</td>\n",
       "      <td>0.626410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>most_frequent_RandomForestClassifier_1000_stan...</td>\n",
       "      <td>1.577181</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>0.681137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>most_frequent_RandomForestClassifier_1000_MinMax</td>\n",
       "      <td>1.620185</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>0.638133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>most_frequent_RandomForestClassifier_1000_MaxAbs</td>\n",
       "      <td>1.612452</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>0.645866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model      rmse  \\\n",
       "0                     median_LinearRegression_standard  1.302203   \n",
       "1                       median_LinearRegression_MinMax  1.302203   \n",
       "2                       median_LinearRegression_MaxAbs  1.302203   \n",
       "3                   median_LogisticRegression_standard  1.453444   \n",
       "4                     median_LogisticRegression_MinMax  1.453444   \n",
       "5                     median_LogisticRegression_MaxAbs  1.453444   \n",
       "6                median_DecisionTreeRegressor_standard  1.501157   \n",
       "7                  median_DecisionTreeRegressor_MinMax  1.558356   \n",
       "8                  median_DecisionTreeRegressor_MaxAbs  1.542230   \n",
       "9           median_RandomForestRegressor_n100_standard  1.321711   \n",
       "10            median_RandomForestRegressor_n100_MinMax  1.303534   \n",
       "11            median_RandomForestRegressor_n100_MaxAbs  1.313665   \n",
       "12          median_RandomForestRegressor_n200_standard  1.302207   \n",
       "13            median_RandomForestRegressor_n200_MinMax  1.307043   \n",
       "14            median_RandomForestRegressor_n200_MaxAbs  1.305169   \n",
       "15          median_RandomForestRegressor_n300_standard  1.303589   \n",
       "16            median_RandomForestRegressor_n300_MinMax  1.302185   \n",
       "17            median_RandomForestRegressor_n300_MaxAbs  1.300560   \n",
       "18          median_RandomForestRegressor_n400_standard  1.310178   \n",
       "19            median_RandomForestRegressor_n400_MinMax  1.300976   \n",
       "20            median_RandomForestRegressor_n400_MaxAbs  1.303488   \n",
       "21          median_RandomForestRegressor_n500_standard  1.309877   \n",
       "22            median_RandomForestRegressor_n500_MinMax  1.300604   \n",
       "23            median_RandomForestRegressor_n500_MaxAbs  1.304265   \n",
       "24             median_KNeighborsRegressor_03n_standard  1.538849   \n",
       "25               median_KNeighborsRegressor_03n_MinMax  1.538849   \n",
       "26               median_KNeighborsRegressor_03n_MaxAbs  1.538849   \n",
       "27             median_KNeighborsRegressor_05n_standard  1.338656   \n",
       "28               median_KNeighborsRegressor_05n_MinMax  1.338656   \n",
       "29               median_KNeighborsRegressor_05n_MaxAbs  1.338656   \n",
       "30             median_KNeighborsRegressor_07n_standard  1.312227   \n",
       "31               median_KNeighborsRegressor_07n_MinMax  1.312227   \n",
       "32               median_KNeighborsRegressor_07n_MaxAbs  1.312227   \n",
       "33             median_KNeighborsRegressor_10n_standard  1.360698   \n",
       "34               median_KNeighborsRegressor_10n_MinMax  1.360698   \n",
       "35               median_KNeighborsRegressor_10n_MaxAbs  1.360698   \n",
       "36             median_KNeighborsRegressor_13n_standard  1.340924   \n",
       "37               median_KNeighborsRegressor_13n_MinMax  1.340924   \n",
       "38               median_KNeighborsRegressor_13n_MaxAbs  1.340924   \n",
       "39              median_DecisionTreeClassifier_standard  1.453444   \n",
       "40                median_DecisionTreeClassifier_MinMax  1.405347   \n",
       "41                median_DecisionTreeClassifier_MaxAbs  1.400893   \n",
       "42          median_RandomForestClassifier_250_standard  1.561249   \n",
       "43            median_RandomForestClassifier_250_MinMax  1.581139   \n",
       "44            median_RandomForestClassifier_250_MaxAbs  1.565248   \n",
       "45          median_RandomForestClassifier_500_standard  1.577181   \n",
       "46            median_RandomForestClassifier_500_MinMax  1.581139   \n",
       "47            median_RandomForestClassifier_500_MaxAbs  1.577181   \n",
       "48          median_RandomForestClassifier_750_standard  1.561249   \n",
       "49            median_RandomForestClassifier_750_MinMax  1.592953   \n",
       "50            median_RandomForestClassifier_750_MaxAbs  1.553222   \n",
       "51         median_RandomForestClassifier_1000_standard  1.565248   \n",
       "52           median_RandomForestClassifier_1000_MinMax  1.565248   \n",
       "53           median_RandomForestClassifier_1000_MaxAbs  1.581139   \n",
       "54                      mean_LinearRegression_standard  1.296255   \n",
       "55                        mean_LinearRegression_MinMax  1.296255   \n",
       "56                        mean_LinearRegression_MaxAbs  1.296255   \n",
       "57                    mean_LogisticRegression_standard  1.462019   \n",
       "58                      mean_LogisticRegression_MinMax  1.462019   \n",
       "59                      mean_LogisticRegression_MaxAbs  1.462019   \n",
       "60                 mean_DecisionTreeRegressor_standard  1.693738   \n",
       "61                   mean_DecisionTreeRegressor_MinMax  1.645068   \n",
       "62                   mean_DecisionTreeRegressor_MaxAbs  1.544142   \n",
       "63            mean_RandomForestRegressor_n100_standard  1.304927   \n",
       "64              mean_RandomForestRegressor_n100_MinMax  1.320018   \n",
       "65              mean_RandomForestRegressor_n100_MaxAbs  1.305404   \n",
       "66            mean_RandomForestRegressor_n200_standard  1.325625   \n",
       "67              mean_RandomForestRegressor_n200_MinMax  1.306115   \n",
       "68              mean_RandomForestRegressor_n200_MaxAbs  1.315323   \n",
       "69            mean_RandomForestRegressor_n300_standard  1.317036   \n",
       "70              mean_RandomForestRegressor_n300_MinMax  1.309261   \n",
       "71              mean_RandomForestRegressor_n300_MaxAbs  1.310433   \n",
       "72            mean_RandomForestRegressor_n400_standard  1.315460   \n",
       "73              mean_RandomForestRegressor_n400_MinMax  1.307779   \n",
       "74              mean_RandomForestRegressor_n400_MaxAbs  1.322402   \n",
       "75            mean_RandomForestRegressor_n500_standard  1.310716   \n",
       "76              mean_RandomForestRegressor_n500_MinMax  1.311217   \n",
       "77              mean_RandomForestRegressor_n500_MaxAbs  1.314086   \n",
       "78               mean_KNeighborsRegressor_03n_standard  1.530251   \n",
       "79                 mean_KNeighborsRegressor_03n_MinMax  1.530251   \n",
       "80                 mean_KNeighborsRegressor_03n_MaxAbs  1.530251   \n",
       "81               mean_KNeighborsRegressor_05n_standard  1.383293   \n",
       "82                 mean_KNeighborsRegressor_05n_MinMax  1.383293   \n",
       "83                 mean_KNeighborsRegressor_05n_MaxAbs  1.383293   \n",
       "84               mean_KNeighborsRegressor_07n_standard  1.338881   \n",
       "85                 mean_KNeighborsRegressor_07n_MinMax  1.338881   \n",
       "86                 mean_KNeighborsRegressor_07n_MaxAbs  1.338881   \n",
       "87               mean_KNeighborsRegressor_10n_standard  1.337068   \n",
       "88                 mean_KNeighborsRegressor_10n_MinMax  1.337068   \n",
       "89                 mean_KNeighborsRegressor_10n_MaxAbs  1.337068   \n",
       "90               mean_KNeighborsRegressor_13n_standard  1.346264   \n",
       "91                 mean_KNeighborsRegressor_13n_MinMax  1.346264   \n",
       "92                 mean_KNeighborsRegressor_13n_MaxAbs  1.346264   \n",
       "93                mean_DecisionTreeClassifier_standard  1.400893   \n",
       "94                  mean_DecisionTreeClassifier_MinMax  1.440486   \n",
       "95                  mean_DecisionTreeClassifier_MaxAbs  1.418626   \n",
       "96            mean_RandomForestClassifier_250_standard  1.537043   \n",
       "97              mean_RandomForestClassifier_250_MinMax  1.573213   \n",
       "98              mean_RandomForestClassifier_250_MaxAbs  1.585087   \n",
       "99            mean_RandomForestClassifier_500_standard  1.585087   \n",
       "100             mean_RandomForestClassifier_500_MinMax  1.569235   \n",
       "101             mean_RandomForestClassifier_500_MaxAbs  1.549193   \n",
       "102           mean_RandomForestClassifier_750_standard  1.569235   \n",
       "103             mean_RandomForestClassifier_750_MinMax  1.585087   \n",
       "104             mean_RandomForestClassifier_750_MaxAbs  1.569235   \n",
       "105          mean_RandomForestClassifier_1000_standard  1.569235   \n",
       "106            mean_RandomForestClassifier_1000_MinMax  1.569235   \n",
       "107            mean_RandomForestClassifier_1000_MaxAbs  1.573213   \n",
       "108            most_frequent_LinearRegression_standard  1.307430   \n",
       "109              most_frequent_LinearRegression_MinMax  1.307430   \n",
       "110              most_frequent_LinearRegression_MaxAbs  1.307430   \n",
       "111          most_frequent_LogisticRegression_standard  1.466288   \n",
       "112            most_frequent_LogisticRegression_MinMax  1.466288   \n",
       "113            most_frequent_LogisticRegression_MaxAbs  1.466288   \n",
       "114       most_frequent_DecisionTreeRegressor_standard  1.556237   \n",
       "115         most_frequent_DecisionTreeRegressor_MinMax  1.536026   \n",
       "116         most_frequent_DecisionTreeRegressor_MaxAbs  1.556237   \n",
       "117  most_frequent_RandomForestRegressor_n100_standard  1.323340   \n",
       "118    most_frequent_RandomForestRegressor_n100_MinMax  1.310169   \n",
       "119    most_frequent_RandomForestRegressor_n100_MaxAbs  1.316054   \n",
       "120  most_frequent_RandomForestRegressor_n200_standard  1.327530   \n",
       "121    most_frequent_RandomForestRegressor_n200_MinMax  1.304002   \n",
       "122    most_frequent_RandomForestRegressor_n200_MaxAbs  1.310074   \n",
       "123  most_frequent_RandomForestRegressor_n300_standard  1.315597   \n",
       "124    most_frequent_RandomForestRegressor_n300_MinMax  1.307871   \n",
       "125    most_frequent_RandomForestRegressor_n300_MaxAbs  1.302896   \n",
       "126  most_frequent_RandomForestRegressor_n400_standard  1.308191   \n",
       "127    most_frequent_RandomForestRegressor_n400_MinMax  1.307096   \n",
       "128    most_frequent_RandomForestRegressor_n400_MaxAbs  1.306888   \n",
       "129  most_frequent_RandomForestRegressor_n500_standard  1.317732   \n",
       "130    most_frequent_RandomForestRegressor_n500_MinMax  1.309665   \n",
       "131    most_frequent_RandomForestRegressor_n500_MaxAbs  1.305953   \n",
       "132     most_frequent_KNeighborsRegressor_03n_standard  1.419605   \n",
       "133       most_frequent_KNeighborsRegressor_03n_MinMax  1.419605   \n",
       "134       most_frequent_KNeighborsRegressor_03n_MaxAbs  1.419605   \n",
       "135     most_frequent_KNeighborsRegressor_05n_standard  1.279258   \n",
       "136       most_frequent_KNeighborsRegressor_05n_MinMax  1.279258   \n",
       "137       most_frequent_KNeighborsRegressor_05n_MaxAbs  1.279258   \n",
       "138     most_frequent_KNeighborsRegressor_07n_standard  1.283530   \n",
       "139       most_frequent_KNeighborsRegressor_07n_MinMax  1.283530   \n",
       "140       most_frequent_KNeighborsRegressor_07n_MaxAbs  1.283530   \n",
       "141     most_frequent_KNeighborsRegressor_10n_standard  1.332010   \n",
       "142       most_frequent_KNeighborsRegressor_10n_MinMax  1.332010   \n",
       "143       most_frequent_KNeighborsRegressor_10n_MaxAbs  1.332010   \n",
       "144     most_frequent_KNeighborsRegressor_13n_standard  1.340703   \n",
       "145       most_frequent_KNeighborsRegressor_13n_MinMax  1.340703   \n",
       "146       most_frequent_KNeighborsRegressor_13n_MaxAbs  1.340703   \n",
       "147      most_frequent_DecisionTreeClassifier_standard  1.400893   \n",
       "148        most_frequent_DecisionTreeClassifier_MinMax  1.400893   \n",
       "149        most_frequent_DecisionTreeClassifier_MaxAbs  1.396424   \n",
       "150  most_frequent_RandomForestClassifier_250_standard  1.612452   \n",
       "151    most_frequent_RandomForestClassifier_250_MinMax  1.612452   \n",
       "152    most_frequent_RandomForestClassifier_250_MaxAbs  1.577181   \n",
       "153  most_frequent_RandomForestClassifier_500_standard  1.624038   \n",
       "154    most_frequent_RandomForestClassifier_500_MinMax  1.585087   \n",
       "155    most_frequent_RandomForestClassifier_500_MaxAbs  1.589025   \n",
       "156  most_frequent_RandomForestClassifier_750_standard  1.612452   \n",
       "157    most_frequent_RandomForestClassifier_750_MinMax  1.577181   \n",
       "158    most_frequent_RandomForestClassifier_750_MaxAbs  1.612452   \n",
       "159  most_frequent_RandomForestClassifier_1000_stan...  1.577181   \n",
       "160   most_frequent_RandomForestClassifier_1000_MinMax  1.620185   \n",
       "161   most_frequent_RandomForestClassifier_1000_MaxAbs  1.612452   \n",
       "\n",
       "                                   models_w_Attributes  test_rmse     delta  \n",
       "0                      LinearRegression(positive=True)   1.550734  0.248530  \n",
       "1                      LinearRegression(positive=True)   1.550734  0.248530  \n",
       "2                      LinearRegression(positive=True)   1.550734  0.248530  \n",
       "3                                 LogisticRegression()   1.942936  0.489492  \n",
       "4                                 LogisticRegression()   1.942936  0.489492  \n",
       "5                                 LogisticRegression()   1.942936  0.489492  \n",
       "6                              DecisionTreeRegressor()   2.078912  0.577755  \n",
       "7                              DecisionTreeRegressor()   2.078912  0.520556  \n",
       "8                              DecisionTreeRegressor()   2.078912  0.536682  \n",
       "9    (DecisionTreeRegressor(max_features='auto', ra...   1.884003  0.562292  \n",
       "10   (DecisionTreeRegressor(max_features='auto', ra...   1.884003  0.580469  \n",
       "11   (DecisionTreeRegressor(max_features='auto', ra...   1.884003  0.570339  \n",
       "12   (DecisionTreeRegressor(max_features='auto', ra...   1.873733  0.571526  \n",
       "13   (DecisionTreeRegressor(max_features='auto', ra...   1.873733  0.566689  \n",
       "14   (DecisionTreeRegressor(max_features='auto', ra...   1.873733  0.568564  \n",
       "15   (DecisionTreeRegressor(max_features='auto', ra...   1.867207  0.563618  \n",
       "16   (DecisionTreeRegressor(max_features='auto', ra...   1.867207  0.565022  \n",
       "17   (DecisionTreeRegressor(max_features='auto', ra...   1.867207  0.566646  \n",
       "18   (DecisionTreeRegressor(max_features='auto', ra...   1.875839  0.565661  \n",
       "19   (DecisionTreeRegressor(max_features='auto', ra...   1.875839  0.574863  \n",
       "20   (DecisionTreeRegressor(max_features='auto', ra...   1.875839  0.572351  \n",
       "21   (DecisionTreeRegressor(max_features='auto', ra...   1.873696  0.563818  \n",
       "22   (DecisionTreeRegressor(max_features='auto', ra...   1.873696  0.573092  \n",
       "23   (DecisionTreeRegressor(max_features='auto', ra...   1.873696  0.569431  \n",
       "24                  KNeighborsRegressor(n_neighbors=3)   1.907223  0.368374  \n",
       "25                  KNeighborsRegressor(n_neighbors=3)   1.907223  0.368374  \n",
       "26                  KNeighborsRegressor(n_neighbors=3)   1.907223  0.368374  \n",
       "27                               KNeighborsRegressor()   1.749143  0.410487  \n",
       "28                               KNeighborsRegressor()   1.749143  0.410487  \n",
       "29                               KNeighborsRegressor()   1.749143  0.410487  \n",
       "30                  KNeighborsRegressor(n_neighbors=7)   1.660541  0.348315  \n",
       "31                  KNeighborsRegressor(n_neighbors=7)   1.660541  0.348315  \n",
       "32                  KNeighborsRegressor(n_neighbors=7)   1.660541  0.348315  \n",
       "33                 KNeighborsRegressor(n_neighbors=10)   1.624846  0.264148  \n",
       "34                 KNeighborsRegressor(n_neighbors=10)   1.624846  0.264148  \n",
       "35                 KNeighborsRegressor(n_neighbors=10)   1.624846  0.264148  \n",
       "36                 KNeighborsRegressor(n_neighbors=13)   1.608732  0.267808  \n",
       "37                 KNeighborsRegressor(n_neighbors=13)   1.608732  0.267808  \n",
       "38                 KNeighborsRegressor(n_neighbors=13)   1.608732  0.267808  \n",
       "39                            DecisionTreeClassifier()   2.121320  0.667876  \n",
       "40                            DecisionTreeClassifier()   2.121320  0.715973  \n",
       "41                            DecisionTreeClassifier()   2.121320  0.720428  \n",
       "42   (DecisionTreeClassifier(max_features='auto', r...   2.345208  0.783958  \n",
       "43   (DecisionTreeClassifier(max_features='auto', r...   2.345208  0.764069  \n",
       "44   (DecisionTreeClassifier(max_features='auto', r...   2.345208  0.779960  \n",
       "45   (DecisionTreeClassifier(max_features='auto', r...   2.205108  0.627927  \n",
       "46   (DecisionTreeClassifier(max_features='auto', r...   2.205108  0.623969  \n",
       "47   (DecisionTreeClassifier(max_features='auto', r...   2.205108  0.627927  \n",
       "48   (DecisionTreeClassifier(max_features='auto', r...   2.213594  0.652345  \n",
       "49   (DecisionTreeClassifier(max_features='auto', r...   2.213594  0.620641  \n",
       "50   (DecisionTreeClassifier(max_features='auto', r...   2.213594  0.660372  \n",
       "51   (DecisionTreeClassifier(max_features='auto', r...   2.224860  0.659612  \n",
       "52   (DecisionTreeClassifier(max_features='auto', r...   2.224860  0.659612  \n",
       "53   (DecisionTreeClassifier(max_features='auto', r...   2.224860  0.643721  \n",
       "54                     LinearRegression(positive=True)   1.549145  0.252890  \n",
       "55                     LinearRegression(positive=True)   1.549145  0.252890  \n",
       "56                     LinearRegression(positive=True)   1.549145  0.252890  \n",
       "57                                LogisticRegression()   1.942936  0.480917  \n",
       "58                                LogisticRegression()   1.942936  0.480917  \n",
       "59                                LogisticRegression()   1.942936  0.480917  \n",
       "60                             DecisionTreeRegressor()   2.082667  0.388928  \n",
       "61                             DecisionTreeRegressor()   2.082667  0.437598  \n",
       "62                             DecisionTreeRegressor()   2.082667  0.538524  \n",
       "63   (DecisionTreeRegressor(max_features='auto', ra...   1.884190  0.579263  \n",
       "64   (DecisionTreeRegressor(max_features='auto', ra...   1.884190  0.564172  \n",
       "65   (DecisionTreeRegressor(max_features='auto', ra...   1.884190  0.578786  \n",
       "66   (DecisionTreeRegressor(max_features='auto', ra...   1.876704  0.551079  \n",
       "67   (DecisionTreeRegressor(max_features='auto', ra...   1.876704  0.570588  \n",
       "68   (DecisionTreeRegressor(max_features='auto', ra...   1.876704  0.561381  \n",
       "69   (DecisionTreeRegressor(max_features='auto', ra...   1.872171  0.555134  \n",
       "70   (DecisionTreeRegressor(max_features='auto', ra...   1.872171  0.562909  \n",
       "71   (DecisionTreeRegressor(max_features='auto', ra...   1.872171  0.561738  \n",
       "72   (DecisionTreeRegressor(max_features='auto', ra...   1.878140  0.562680  \n",
       "73   (DecisionTreeRegressor(max_features='auto', ra...   1.878140  0.570361  \n",
       "74   (DecisionTreeRegressor(max_features='auto', ra...   1.878140  0.555738  \n",
       "75   (DecisionTreeRegressor(max_features='auto', ra...   1.879407  0.568692  \n",
       "76   (DecisionTreeRegressor(max_features='auto', ra...   1.879407  0.568191  \n",
       "77   (DecisionTreeRegressor(max_features='auto', ra...   1.879407  0.565321  \n",
       "78                  KNeighborsRegressor(n_neighbors=3)   1.914129  0.383878  \n",
       "79                  KNeighborsRegressor(n_neighbors=3)   1.914129  0.383878  \n",
       "80                  KNeighborsRegressor(n_neighbors=3)   1.914129  0.383878  \n",
       "81                               KNeighborsRegressor()   1.765078  0.381785  \n",
       "82                               KNeighborsRegressor()   1.765078  0.381785  \n",
       "83                               KNeighborsRegressor()   1.765078  0.381785  \n",
       "84                  KNeighborsRegressor(n_neighbors=7)   1.652225  0.313344  \n",
       "85                  KNeighborsRegressor(n_neighbors=7)   1.652225  0.313344  \n",
       "86                  KNeighborsRegressor(n_neighbors=7)   1.652225  0.313344  \n",
       "87                 KNeighborsRegressor(n_neighbors=10)   1.637300  0.300232  \n",
       "88                 KNeighborsRegressor(n_neighbors=10)   1.637300  0.300232  \n",
       "89                 KNeighborsRegressor(n_neighbors=10)   1.637300  0.300232  \n",
       "90                 KNeighborsRegressor(n_neighbors=13)   1.595876  0.249612  \n",
       "91                 KNeighborsRegressor(n_neighbors=13)   1.595876  0.249612  \n",
       "92                 KNeighborsRegressor(n_neighbors=13)   1.595876  0.249612  \n",
       "93                            DecisionTreeClassifier()   2.121320  0.720428  \n",
       "94                            DecisionTreeClassifier()   2.121320  0.680834  \n",
       "95                            DecisionTreeClassifier()   2.121320  0.702694  \n",
       "96   (DecisionTreeClassifier(max_features='auto', r...   2.339872  0.802829  \n",
       "97   (DecisionTreeClassifier(max_features='auto', r...   2.339872  0.766659  \n",
       "98   (DecisionTreeClassifier(max_features='auto', r...   2.339872  0.754785  \n",
       "99   (DecisionTreeClassifier(max_features='auto', r...   2.213594  0.628508  \n",
       "100  (DecisionTreeClassifier(max_features='auto', r...   2.213594  0.644359  \n",
       "101  (DecisionTreeClassifier(max_features='auto', r...   2.213594  0.664401  \n",
       "102  (DecisionTreeClassifier(max_features='auto', r...   2.222049  0.652813  \n",
       "103  (DecisionTreeClassifier(max_features='auto', r...   2.222049  0.636962  \n",
       "104  (DecisionTreeClassifier(max_features='auto', r...   2.222049  0.652813  \n",
       "105  (DecisionTreeClassifier(max_features='auto', r...   2.230471  0.661235  \n",
       "106  (DecisionTreeClassifier(max_features='auto', r...   2.230471  0.661235  \n",
       "107  (DecisionTreeClassifier(max_features='auto', r...   2.230471  0.657258  \n",
       "108                    LinearRegression(positive=True)   1.544924  0.237494  \n",
       "109                    LinearRegression(positive=True)   1.544924  0.237494  \n",
       "110                    LinearRegression(positive=True)   1.544924  0.237494  \n",
       "111                               LogisticRegression()   1.936492  0.470204  \n",
       "112                               LogisticRegression()   1.936492  0.470204  \n",
       "113                               LogisticRegression()   1.936492  0.470204  \n",
       "114                            DecisionTreeRegressor()   2.137463  0.581226  \n",
       "115                            DecisionTreeRegressor()   2.137463  0.601438  \n",
       "116                            DecisionTreeRegressor()   2.137463  0.581226  \n",
       "117  (DecisionTreeRegressor(max_features='auto', ra...   1.870812  0.547472  \n",
       "118  (DecisionTreeRegressor(max_features='auto', ra...   1.870812  0.560644  \n",
       "119  (DecisionTreeRegressor(max_features='auto', ra...   1.870812  0.554759  \n",
       "120  (DecisionTreeRegressor(max_features='auto', ra...   1.876658  0.549128  \n",
       "121  (DecisionTreeRegressor(max_features='auto', ra...   1.876658  0.572656  \n",
       "122  (DecisionTreeRegressor(max_features='auto', ra...   1.876658  0.566584  \n",
       "123  (DecisionTreeRegressor(max_features='auto', ra...   1.873570  0.557973  \n",
       "124  (DecisionTreeRegressor(max_features='auto', ra...   1.873570  0.565699  \n",
       "125  (DecisionTreeRegressor(max_features='auto', ra...   1.873570  0.570673  \n",
       "126  (DecisionTreeRegressor(max_features='auto', ra...   1.870013  0.561822  \n",
       "127  (DecisionTreeRegressor(max_features='auto', ra...   1.870013  0.562917  \n",
       "128  (DecisionTreeRegressor(max_features='auto', ra...   1.870013  0.563125  \n",
       "129  (DecisionTreeRegressor(max_features='auto', ra...   1.872899  0.555168  \n",
       "130  (DecisionTreeRegressor(max_features='auto', ra...   1.872899  0.563235  \n",
       "131  (DecisionTreeRegressor(max_features='auto', ra...   1.872899  0.566946  \n",
       "132                 KNeighborsRegressor(n_neighbors=3)   1.924260  0.504656  \n",
       "133                 KNeighborsRegressor(n_neighbors=3)   1.924260  0.504656  \n",
       "134                 KNeighborsRegressor(n_neighbors=3)   1.924260  0.504656  \n",
       "135                              KNeighborsRegressor()   1.774824  0.495566  \n",
       "136                              KNeighborsRegressor()   1.774824  0.495566  \n",
       "137                              KNeighborsRegressor()   1.774824  0.495566  \n",
       "138                 KNeighborsRegressor(n_neighbors=7)   1.712946  0.429416  \n",
       "139                 KNeighborsRegressor(n_neighbors=7)   1.712946  0.429416  \n",
       "140                 KNeighborsRegressor(n_neighbors=7)   1.712946  0.429416  \n",
       "141                KNeighborsRegressor(n_neighbors=10)   1.643700  0.311690  \n",
       "142                KNeighborsRegressor(n_neighbors=10)   1.643700  0.311690  \n",
       "143                KNeighborsRegressor(n_neighbors=10)   1.643700  0.311690  \n",
       "144                KNeighborsRegressor(n_neighbors=13)   1.595296  0.254593  \n",
       "145                KNeighborsRegressor(n_neighbors=13)   1.595296  0.254593  \n",
       "146                KNeighborsRegressor(n_neighbors=13)   1.595296  0.254593  \n",
       "147                           DecisionTreeClassifier()   2.109502  0.708610  \n",
       "148                           DecisionTreeClassifier()   2.109502  0.708610  \n",
       "149                           DecisionTreeClassifier()   2.109502  0.713078  \n",
       "150  (DecisionTreeClassifier(max_features='auto', r...   2.387467  0.775016  \n",
       "151  (DecisionTreeClassifier(max_features='auto', r...   2.387467  0.775016  \n",
       "152  (DecisionTreeClassifier(max_features='auto', r...   2.387467  0.810286  \n",
       "153  (DecisionTreeClassifier(max_features='auto', r...   2.238861  0.614823  \n",
       "154  (DecisionTreeClassifier(max_features='auto', r...   2.238861  0.653775  \n",
       "155  (DecisionTreeClassifier(max_features='auto', r...   2.238861  0.649836  \n",
       "156  (DecisionTreeClassifier(max_features='auto', r...   2.238861  0.626410  \n",
       "157  (DecisionTreeClassifier(max_features='auto', r...   2.238861  0.661680  \n",
       "158  (DecisionTreeClassifier(max_features='auto', r...   2.238861  0.626410  \n",
       "159  (DecisionTreeClassifier(max_features='auto', r...   2.258318  0.681137  \n",
       "160  (DecisionTreeClassifier(max_features='auto', r...   2.258318  0.638133  \n",
       "161  (DecisionTreeClassifier(max_features='auto', r...   2.258318  0.645866  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_w_atributes = []\n",
    "models_test_rmse = []\n",
    "models_delta = []\n",
    "for model in validation_rmse['model']:\n",
    "    \n",
    "    ## Get the model to get its atributes\n",
    "    mod = (pipes[model].steps)[-1][1]\n",
    "    models_w_atributes.append(mod)\n",
    "    \n",
    "    m = pipes[model]\n",
    "    test_rmse = mean_squared_error(Y_test, m.predict(X_test), squared=False)\n",
    "    models_test_rmse.append(test_rmse)\n",
    "    rmse_val = (validation_rmse.loc[validation_rmse['model'] == model]).rmse\n",
    "    rmse_val = list(rmse_val)[0]\n",
    "    delta = test_rmse - rmse_val\n",
    "    models_delta.append(delta)\n",
    "\n",
    "## Adding column with the modelname and attributes\n",
    "validation_rmse['models_w_Attributes'] = models_w_atributes\n",
    "validation_rmse['test_rmse'] = models_test_rmse\n",
    "validation_rmse['delta'] = models_delta\n",
    "## Picking out the model with smallest RMSE and smallest delta for generalization error\n",
    "\n",
    "best_model = pipes[validation_rmse.loc[np.argmin(validation_rmse.delta), 'model']]\n",
    "\n",
    "print(\"Best Model Validation-RMSE: \")\n",
    "print(validation_rmse.loc[np.argmin(validation_rmse.delta), ['model', 'rmse', 'test_rmse', 'delta']])\n",
    "validation_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813351b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "actual_y_test, predicted_y_test = Y_test, best_model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(14, 9))\n",
    "plt.scatter(\n",
    "    x = range(len(predicted_y_test)),\n",
    "    y = predicted_y_test,\n",
    "    label = f'Predicted Goals\\nRMSE: {round(test_rmse, 4)}',\n",
    "    c = 'b'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    x = range(len(actual_y_test)), \n",
    "    y = actual_y_test,\n",
    "    label = 'Actual Goals',\n",
    "    c = 'r'\n",
    ")\n",
    "plt.plot(\n",
    "    [avg_of_train_data for i in range(len(actual_y_test))],\n",
    "    c = 'black',\n",
    "    label = f'Test_Data Average Goals Scored\\nRMSE: {round(average_prediction_RMSE, 4)}'\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.ylabel(\"#Goals\")\n",
    "plt.xlabel(\"Prediction number\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9567588",
   "metadata": {},
   "source": [
    "### As we see, the model predicts within the accaptable range, where lower bound is 0 and uper bound in theory infinite. As well as the range holds, we see that our predicted data, being the blue scatterplots is well in our range of actual data (0-6 goals). This makes out model trustworthy. The interesting part about our prediction is that the most of the predicted goals scored is in the range between 1 and 2, wichs is because of  the average we calculated earlier, and hence makes sense.\n",
    "\n",
    "We have a RMSE on the best model with the validation data beein ≈1.3 which is average, and corresponding test-RMSE at ≈1.54. If we compare this to the calculated RMSE from the random distribution it is clear that the model is more accurate, with a almost half the RMSE as the normal distributed prediction. Comparing it to the avergae-prediction-method, which has a RMSE of 1.46, our result is not that impressive, although it is slightly better. The test_rmse and validation_rmse makes up the delta of 0.26 which is accaptable, although it is not the best when it comes to getting a perfect generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee66f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing our model for the website beeing created.\n",
    "pickle.dump(best_model, open('app_folder/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da2f3f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Score\n",
       "0      0      1\n",
       "1      1      1\n",
       "2      2      2\n",
       "3      3      1\n",
       "4      4      2\n",
       "5      5      1\n",
       "6      6      1\n",
       "7      7      1\n",
       "8      8      2\n",
       "9      9      1\n",
       "10    10      1\n",
       "11    11      1\n",
       "12    12      2\n",
       "13    13      1\n",
       "14    14      1\n",
       "15    15      1\n",
       "16    16      1\n",
       "17    17      2\n",
       "18    18      2\n",
       "19    19      1\n",
       "20    20      1\n",
       "21    21      2\n",
       "22    22      2\n",
       "23    23      1\n",
       "24    24      2\n",
       "25    25      1\n",
       "26    26      2\n",
       "27    27      1\n",
       "28    28      2\n",
       "29    29      1\n",
       "30    30      2\n",
       "31    31      1\n",
       "32    32      2\n",
       "33    33      1\n",
       "34    34      1\n",
       "35    35      1\n",
       "36    36      1\n",
       "37    37      1\n",
       "38    38      2\n",
       "39    39      1\n",
       "40    40      1\n",
       "41    41      2\n",
       "42    42      1\n",
       "43    43      2\n",
       "44    44      2\n",
       "45    45      1\n",
       "46    46      1\n",
       "47    47      1\n",
       "48    48      2\n",
       "49    49      1\n",
       "50    50      2\n",
       "51    51      1\n",
       "52    52      2\n",
       "53    53      1\n",
       "54    54      2\n",
       "55    55      1\n",
       "56    56      1\n",
       "57    57      1\n",
       "58    58      2\n",
       "59    59      1\n",
       "60    60      1\n",
       "61    61      1\n",
       "62    62      2\n",
       "63    63      1\n",
       "64    64      2\n",
       "65    65      1\n",
       "66    66      1\n",
       "67    67      2\n",
       "68    68      1\n",
       "69    69      1\n",
       "70    70      1\n",
       "71    71      1\n",
       "72    72      2\n",
       "73    73      1\n",
       "74    74      1\n",
       "75    75      1\n",
       "76    76      1\n",
       "77    77      1\n",
       "78    78      2\n",
       "79    79      1\n",
       "80    80      1\n",
       "81    81      1\n",
       "82    82      1\n",
       "83    83      1\n",
       "84    84      2\n",
       "85    85      1\n",
       "86    86      1\n",
       "87    87      2\n",
       "88    88      2\n",
       "89    89      1\n",
       "90    90      2\n",
       "91    91      1\n",
       "92    92      2\n",
       "93    93      1\n",
       "94    94      2\n",
       "95    95      1\n",
       "96    96      1\n",
       "97    97      2\n",
       "98    98      1\n",
       "99    99      1\n",
       "100  100      1\n",
       "101  101      2\n",
       "102  102      1\n",
       "103  103      1\n",
       "104  104      2\n",
       "105  105      1\n",
       "106  106      1\n",
       "107  107      1\n",
       "108  108      2\n",
       "109  109      1\n",
       "110  110      2\n",
       "111  111      1\n",
       "112  112      2\n",
       "113  113      1\n",
       "114  114      1\n",
       "115  115      1\n",
       "116  116      1\n",
       "117  117      1\n",
       "118  118      1\n",
       "119  119      1\n",
       "120  120      1\n",
       "121  121      1\n",
       "122  122      1\n",
       "123  123      1\n",
       "124  124      2\n",
       "125  125      1\n",
       "126  126      1\n",
       "127  127      1\n",
       "128  128      1\n",
       "129  129      1\n",
       "130  130      2\n",
       "131  131      1\n",
       "132  132      1\n",
       "133  133      2\n",
       "134  134      2\n",
       "135  135      1\n",
       "136  136      2\n",
       "137  137      1\n",
       "138  138      2\n",
       "139  139      1\n",
       "140  140      2\n",
       "141  141      1\n",
       "142  142      2\n",
       "143  143      1\n",
       "144  144      1\n",
       "145  145      1\n",
       "146  146      1\n",
       "147  147      1\n",
       "148  148      2\n",
       "149  149      1\n",
       "150  150      2\n",
       "151  151      1\n",
       "152  152      2\n",
       "153  153      1\n",
       "154  154      2\n",
       "155  155      1\n",
       "156  156      1\n",
       "157  157      1\n",
       "158  158      1\n",
       "159  159      1\n",
       "160  160      1\n",
       "161  161      2\n",
       "162  162      1\n",
       "163  163      1\n",
       "164  164      1\n",
       "165  165      1\n",
       "166  166      1\n",
       "167  167      1\n",
       "168  168      1\n",
       "169  169      1\n",
       "170  170      2\n",
       "171  171      1\n",
       "172  172      2\n",
       "173  173      1\n",
       "174  174      2\n",
       "175  175      1\n",
       "176  176      1\n",
       "177  177      1\n",
       "178  178      2\n",
       "179  179      1\n",
       "180  180      2\n",
       "181  181      1\n",
       "182  182      2\n",
       "183  183      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prediction and the creation of the CSV-file with ur output from the predication.\n",
    "X_test_2020 = test_games[numeric_features]\n",
    "prediction = best_model.predict(X_test_2020)\n",
    "prediction = [round(x) for x in prediction]\n",
    "test_games['Score'] = prediction\n",
    "test_games['ID'] = test_games.index\n",
    "pred_cols = test_games[['ID', 'Score']]\n",
    "pred_cols.to_csv(\"predictions.csv\", index = False)\n",
    "pred_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c24c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
